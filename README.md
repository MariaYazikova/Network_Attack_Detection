## Описание проекта

Проект реализует инференс модели XGBoost на C++ для классификации сетевых атак по данным CICIDS2017.

## Структура

- **inputs/** - тестовые входные данные для инференса:
  - `generate_test_inputs.py` - скрипт генерации тестовых входных данных
  - `inputs.csv` - файл с тестовыми входными данными
- **mapping/** - метаданные для создания входных данных:
  - `export_metadata.py` - скрипт генерации файлов с метаданными из подготовленного набора данных
  - `features.txt` - список признаков
  - `classes.txt` - список классов атак
- **metrics/** - оценка качества моделей:
  - `plots/` - графики confusion matrix
  - `metrics.py` - скрипт расчета метрик
  - `results.txt` - результаты метрик
- **models/** - модели:
  - `saved/` - обученные модели
  - `logreg_model.py, rf_model.py, xgb_model.py` - скрипты обучения и сохранения моделей
- **xgboost/** - необходимые файлы библиотеки [XGBoost](https://github.com/dmlc/xgboost) для C++ инференса
- **data_prep.py** - скрипт подготовки данных
- **export_xgb_model.py** - скрипт конвертации обученной модели XGBoost в JSON для инференса
- **xgb_inference.cpp** - C++ код инференса: использует `inputs.csv` и JSON модель для предсказания классов атак

## Описание работы

1. **Выбор датасета:**
   - Для обучения модели использовался датасет с [Cleaned CICID2017 c Kaggle](https://www.kaggle.com/datasets/ernie55ernie/cleaned-cicids2017) - очищенная и подготовленная версия официального CICIDS2017. Он содержит реальные сетевые трафики с нормальными соединениями и различными типами атак и широко применяется для разработки систем обнаружения вторжений.
2. **Подготовка данных:**
   - Реализована в `data_prep.py`.
   - Из исходного датасета были отобраны 8 классов: BENIGN, DoS Slowloris, DoS Slowhttptest, DoS Hulk, DoS GoldenEye, Infiltration - Portscan, Portscan, DDoS. Метки были закодированы, числовые признаки - масштабированы.
   - Данные разделены на обучающую и тестовую выборки с сохранением пропорций классов.
   - После выполнения скрипта формируется `datasets/prepared_data.pkl` с подготовленными данными.
3. **Обучение моделей:**
   - С учетом особенностей данных (82 числовых признака, дисбаланс классов, многоклассовая классификация) были выбраны алгоритмы:
     - **Logistic Regression** - простая линейная модель, используемая как базовый ориентир. Применен параметр `class_weight='balanced'`, компенсирующий дисбаланс классов.
     - **Random Forest** - ансамбль решающих деревьев, устойчивый к дисбалансу и хорошо работающий с большим количеством числовых признаков и нелинейными зависимостями. Так же использовался параметр для балансировки весов.
     - **XGBoost** - градиентный бустинг над деревьями решений, часто показывающий лучшие результатов при работе с несбалансированными и многоклассовыми данными.
   - Скрипты обучения находятся в `models/`, обученные модели - в `models/saved/`.
4. **Оценка качества моделей:**
   - Выполнена с помощью скрипта `metrics/metrics.py`.
   - Для каждой модели рассчитаны метрики:
     - **Accuracy** - общая точность. Приведена для полноты картины, при дисбалансе может давать искаженную оценку качества модели.
     - **Balanced Accuracy** - средняя точность по классам.
     - **Precision, Recall, F1 (macro и weighted)** - метрики точности, полноты и гармонического среднего как по классам, так и с учетом их весов.
   - Результаты сохранены в `metrics/results.txt`.
   - XGBoost показала лучшие результаты по всем метрикам с небольшим отрывом от Random Forest и была выбрана для инференса.
   - Дополнительно построены матрицы ошибок, которые визуально идентичны для всех моделей. Их можно посмотреть в `metrics/plots/`.
5. **Инференс в C++:**
   - Используется сохраненная модель `xgb_model.json`, экспортированная в JSON с помощью `export_xgb_model.py`.
   - На вход подаются данные из `inputs/inputs.csv`, сформированные скриптом `generate_test_inputs.py`. Файл содержит 8 строк - по одной для каждого класса, данные взяты из тестовой выборки.
   - В файле выполняется:
   1. Загрузка модели через XGBoost C API.
   2. Чтение и преобразование входных данных в матрицу признаков.
   3. Выполнение предсказания классов для каждой строки.
   - Для тестовых примеров модель корректно предсказала все 8 классов:
   ```
     Row 0: Predicted class = 0 (BENIGN)
     Row 1: Predicted class = 1 (DoS Slowloris)
     Row 2: Predicted class = 2 (DoS Slowhttptest)
     Row 3: Predicted class = 3 (DoS Hulk)
     Row 4: Predicted class = 4 (DoS GoldenEye)
     Row 5: Predicted class = 5 (Infiltration - Portscan)
     Row 6: Predicted class = 6 (Portscan)
     Row 7: Predicted class = 7 (DDoS)
   ```

## Инструкция по сборке и запуску

1. **Настройка среды C++**:

   - Убедитесь, что установлен MinGW (g++)
   - Библиотека `xgboost.dll` должна быть доступна при запуске программы:
     - Вариант 1: скопировать `xgboost.dll` в папку с `.cpp` файлом
     - Вариант 2: добавить путь к `xgboost/lib` локально в настройках VS Code (для Windows) - файл `.vscode/settings.json`:
     ```json
     {
       "terminal.integrated.env.windows": {
         "PATH": "${workspaceFolder}/xgboost/lib"
       },
       "files.associations": {
         "string": "cpp"
       }
     }
     ```

2. **Сборка и запуск инференса**:

   - Для сборки выполните:

   ```bash
   g++ xgb_inference.cpp -o xgb_inference.exe -Ixgboost/include -Lxgboost/lib -lxgboost
   ```

   - Для запуска:

   ```
   .\xgb_inference.exe
   ```

3. **Подготовка данных** (опционально, данные не включены в репозиторий):

   - Скачать исходный датасет [Cleaned CICID2017 c KAggle](https://www.kaggle.com/datasets/ernie55ernie/cleaned-cicids2017).
   - Сохранить файл `cleaned_improved_cicids2017.csv` в папку `datasets/`
   - Запустить:
     ```bash
     python data_prep.py
     ```
   - В папке `datasets/` появится `prepared_data.pkl`.
